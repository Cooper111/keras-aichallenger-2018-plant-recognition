#coding=utf-8
from __future__ import print_function
import os
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau
from keras.layers import Dense, GlobalAveragePooling2D,Flatten,Dropout,PReLU,BatchNormalization,Activation
from keras.models import Model
from keras.layers import Input
from vgg16 import VGGNet
from inceptionv3 import Inception_v3
from keras.backend.tensorflow_backend import set_session
import tensorflow as tf
from inception_resnet_v2 import InceptionResNetV2
from mobilenet_v2 import MobileNetv2
from resnet50 import ResNet50
from inception_v4 import inception_v4
from resnet34 import ResNet34
from vgg19 import VGG19
from densenet121 import DenseNet
import os
from xception import Xception
from shufflenetv2 import ShuffleNetV2
from resnet_attention_56 import Resnet_Attention_56
from se_resnet import SEResNet50
from squeezenet import SqueezeNet
from se_resnext import SEResNext
from densenet161 import DenseNet161
from custom_network import Custom_Network
from nasnet import NASNet
from keras.applications import imagenet_utils
from keras.callbacks import TensorBoard
import time
import argparse
import numpy as np
from resnet18 import ResnetBuilder


train_data_dir = '/home/eric/data/plant/ai_challenger_pdr2018_trainingset_20181023/AgriculturalDisease_trainingset/data'
test_data_dir = '/home/eric/data/plant/ai_challenger_pdr2018_validationset_20181023/AgriculturalDisease_validationset/data'
# test_data_dir='/home/eric/Documents/AI_Challenger_2018/Baselines/plant_disease_recognition2018_baseline/keras/data'
class_dictionary={}

# dimensions of our images.
IMAGE_SIZE=(265,265)

CROP_LENGTH=224
charset_size = 61
nb_validation_samples = 4540
nb_train_samples = 31718
nb_epoch = 300
batch_size = 64

img_width, img_height = CROP_LENGTH,CROP_LENGTH

classes=[]
with open("labels.txt","r") as f:
    for line in f.readlines():
        classes.append(line.strip("\n").split(" ")[0])

def random_crop(img, random_crop_size):
    # Note: image_data_format is 'channel_last'
    assert img.shape[2] == 3
    height, width = img.shape[0], img.shape[1]
    dy, dx = random_crop_size
    x = np.random.randint(0, width - dx + 1)
    y = np.random.randint(0, height - dy + 1)
    return img[y:(y+dy), x:(x+dx), :]

def crop_generator(batches, crop_length):
    """Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator.
    """
    while True:
        batch_x, batch_y = next(batches)
        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))
        for i in range(batch_x.shape[0]):
            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))
        yield (batch_crops, batch_y)

def train(model,model_name='vgg'):
    train_datagen = ImageDataGenerator(1./255,
                              horizontal_flip=True,
                              rotation_range=40,
                              width_shift_range=0.1,
                              height_shift_range=0.1,
                              shear_range=0.2,
                              zoom_range=0.2,)
    test_datagen = ImageDataGenerator(1./255)
    train_generator = train_datagen.flow_from_directory(
        train_data_dir,
        shuffle=True,
        target_size=IMAGE_SIZE,
        batch_size=batch_size,
        color_mode="rgb",
        classes=classes,
        class_mode='categorical',
        seed=42)
    # print(train_generator.class_indices)
    # imgs, labels = next(train_generator)
    # print(imgs[0])
    # print(labels[0])
    # add random crop
    
    
    validation_generator = test_datagen.flow_from_directory(
        test_data_dir,
        target_size=IMAGE_SIZE,
        batch_size=batch_size,
        color_mode="rgb",
        classes=classes,
        class_mode='categorical',
        seed=42)
    # print(validation_generator.class_indices)

    train_generator = crop_generator(train_generator, CROP_LENGTH)
    validation_generator=crop_generator(validation_generator,CROP_LENGTH)

    save_path=os.path.join('trained_model',model_name)
    if(not os.path.exists(save_path)):
        os.mkdir(save_path)
    tensorboard = TensorBoard(log_dir='./logs/{}'.format(model_name), batch_size=batch_size)
    model_names = (os.path.join(save_path,model_name+'.{epoch:02d}-{val_acc:.4f}.hdf5'))
    model_checkpoint = ModelCheckpoint(model_names,
                                    monitor='val_acc',
                                    verbose=1,
                                    save_best_only=True,
                                    save_weights_only=False)
    reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss', factor=0.1,
                                         patience=10, verbose=1)
    callbacks = [model_checkpoint,reduce_learning_rate,tensorboard]

    model.compile(loss='categorical_crossentropy',
        optimizer='adam',
        metrics=['accuracy'])
    model.fit_generator(train_generator,
        steps_per_epoch=nb_train_samples//batch_size,
        epochs=nb_epoch,
        callbacks=callbacks,
        validation_data=validation_generator,
        validation_steps=nb_validation_samples // batch_size
      )

# bn + prelu
def bn_prelu(x):
    x = BatchNormalization()(x)
    x = PReLU()(x)
    return x

def train_factory(MODEL_NAME):

    config = tf.ConfigProto()
    config.gpu_options.allocator_type = 'BFC'
    config.gpu_options.allow_growth = True
    set_session(tf.Session(config=config)) 
    # model = CCR(input_shape=(img_width,img_height,1),classes=charset_size)
    # model = LeNet.build(width=img_width, height=img_height, depth=1, classes=charset_size)
    # model = ResNet.build_model(SHAPE=(img_width,img_height,1), classes=charset_size)

    # vgg net 5
    # MODEL_PATH='trained_model/vggnet5.hdf5'
    # model=VGGNet5.vgg(input_shape=(img_width,img_height,1),classes=charset_size)

    model=None
    if(MODEL_NAME=='inception_resnet_v2'):
        model=InceptionResNetV2.inception_resnet_v2(input_shape=(img_width,img_height,3),classes=charset_size,weights='./trained_model/inception_resnet_v2/inception_resnet_v2.12-0.8244.hdf5')
    elif(MODEL_NAME=='xception'):
        # xeception
        model=Xception.Xception((img_width,img_height,3),classes=charset_size)
    elif(MODEL_NAME=='mobilenet_v2'):
        #mobilenet v2
        model=MobileNetv2.MobileNet_v2((img_width,img_height,3),classes=charset_size)
    elif(MODEL_NAME=='inception_v3'):
        #mobilenet v2
        model=Inception_v3.inception((img_width,img_height,3),classes=charset_size)
    elif(MODEL_NAME=='vgg16'):
        model=VGGNet.vgg(input_shape=(img_width,img_height,3),classes=charset_size)
    elif(MODEL_NAME=='vgg19'):
        model=VGG19.VGG19(input_shape=(img_width,img_height,3),classes=charset_size,weights='weights/vgg19_weights_tf_dim_ordering_tf_kernels.h5')
    elif(MODEL_NAME=='resnet50'):
        model=ResNet50.resnet(input_shape=(img_width,img_height,3),classes=charset_size)
    elif(MODEL_NAME=='inception_v4'):
        model=inception_v4.inception_v4(input_shape=(img_width,img_height,3),classes=charset_size)
    elif(MODEL_NAME=='resnet34'):
        model=ResNet34.ResNet34(input_shape=(img_width,img_height,3),classes=charset_size)
    elif(MODEL_NAME=='densenet121'):
        model=DenseNet.DenseNet(input_shape=(img_width,img_height,3),classes=charset_size)
    elif(MODEL_NAME=='densenet161'):
        model=DenseNet.DenseNet(input_shape=(img_width,img_height,3),classes=charset_size)
    elif(MODEL_NAME=='shufflenet_v2'):
        model=ShuffleNetV2.ShuffleNetV2(input_shape=(img_width,img_height,3),classes=charset_size)
    elif(MODEL_NAME=='resnet_attention_56'):
        model=Resnet_Attention_56.Resnet_Attention_56(input_shape=(img_width,img_height,3),classes=charset_size)
    elif(MODEL_NAME=='squeezenet'):
        model=SqueezeNet.SqueezeNet(input_shape=(img_width,img_height,3),classes=charset_size)
    elif(MODEL_NAME=='seresnet50'):
        model=SEResNet50.SEResNet50(input_shape=(img_width,img_height,3),classes=charset_size)
    elif(MODEL_NAME=='se_resnext'):
        model=SEResNext.SEResNext(input_shape=(img_width,img_height,3),classes=charset_size)
    elif(MODEL_NAME=='nasnet'):
        model=NASNet.NASNetLarge(input_shape=(img_width,img_height,3),classes=charset_size)
    elif(MODEL_NAME=='custom'):
        model=Custom_Network.Custom_Network(input_shape=(img_width,img_height,3),classes=charset_size)
    elif(MODEL_NAME=='resnet18'):
        model=ResnetBuilder.build_resnet_18(input_shape=(img_width,img_height,3),num_outputs=charset_size)



    print(model.summary())
    train(model,MODEL_NAME)

    # MODEL_NAME='ShuffleNetV2'
    # model=ShuffleNetV2.ShuffleNetV2((img_width,img_height,3),classes=charset_size)

def make_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('-m',"--model_name",type=str,
            help='select the model name that you want to train')
    return parser.parse_args()

if __name__ == '__main__':
    args = make_args()
    train_factory(args.model_name)
    
# input_tensor = Input(shape=(img_width, img_height, 1))
# base_model = ResNet50(include_top=False,input_tensor=input_tensor,weights=None)
# # add a global spatial average pooling layer
# x = base_model.output
# # and a logistic layer -- let's say we have 100 classes
# predictions = Dense(100, activation='softmax')(x)
# # this is the model we will train
# model = Model(inputs=input_tensor, outputs=predictions)
# for layer in base_model.layers:
#     layer.trainable = False
# model=resnet50_100(feat_dims=1000,out_dims=100)


# model = load_model("./model.h5")



# model.save("./model.h5")

# import os
# from tqdm import tqdm
# import json
# import cv2
# import numpy as np
# from keras.preprocessing.image import img_to_array

# test_dir='/home/eric/data/ai_challenger_plant_train_20170904/AgriculturalDisease_testA/images'
# # test_dir='/home/eric/data/ai_challenger_plant_train_20170904/AgriculturalDisease_validationset/images'
# test_images = os.listdir(test_dir)

# result = []
# for test_image in tqdm(test_images):
#     temp_dict = {}
#     img = cv2.resize(cv2.imread(os.path.join(test_dir,test_image)), (img_width, img_height)).astype(np.float32)
#     img /= 255.0
#     image = img_to_array(img)
#     image = np.expand_dims(image, axis=0)
#     predictions=model.predict(image)
#     sorted_arr=np.argsort(predictions)
#     temp_dict['image_id'] = test_image
#     temp_dict['disease_class'] = int(sorted_arr[:,-1][0])
#     result.append(temp_dict)

# with open('submit.json', 'w') as f:
#     json.dump(result, f)
#     print('write result json, num is %d' % len(result))