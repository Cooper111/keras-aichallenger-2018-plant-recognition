#coding=utf-8
from __future__ import print_function
import os
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau
from keras.layers import Dense, GlobalAveragePooling2D,Flatten,Dropout,PReLU,BatchNormalization,Activation
from keras.models import Model
from keras.layers import Input
from vgg16 import VGGNet
from inceptionv3 import Inception_v3
from keras.backend.tensorflow_backend import set_session
import tensorflow as tf
from inception_resnet_v2 import InceptionResNetV2
from mobilenet_v2 import MobileNetv2
from resnet50 import ResNet50
from inception_v4 import inception_v4
from resnet34 import ResNet34
from vgg19 import VGG19
from densenet121 import DenseNet
import os
from xception import Xception
from shufflenetv2 import ShuffleNetV2
from resnet_attention_56 import Resnet_Attention_56
from keras.applications import imagenet_utils
from keras.callbacks import TensorBoard
import time
import argparse
import numpy as np


train_data_dir = '/home/eric/data/plant/ai_challenger_pdr2018_trainingset_20181023/AgriculturalDisease_trainingset/data'
test_data_dir = '/home/eric/data/plant/ai_challenger_pdr2018_validationset_20181023/AgriculturalDisease_validationset/data'
class_dictionary={}

# dimensions of our images.
IMAGE_SIZE=(256,256)

CROP_LENGTH=224
charset_size = 61
nb_validation_samples = 4540
nb_train_samples = 31718
nb_epoch = 50
batch_size = 16

img_width, img_height = 224, 224

classes=[]
with open("labels.txt","r") as f:
    for line in f.readlines():
        classes.append(line.strip("\n").split(" ")[0])

def random_crop(img, random_crop_size):
    # Note: image_data_format is 'channel_last'
    assert img.shape[2] == 3
    height, width = img.shape[0], img.shape[1]
    dy, dx = random_crop_size
    x = np.random.randint(0, width - dx + 1)
    y = np.random.randint(0, height - dy + 1)
    return img[y:(y+dy), x:(x+dx), :]

def crop_generator(batches, crop_length):
    """Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator.
    """
    while True:
        batch_x, batch_y = next(batches)
        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))
        for i in range(batch_x.shape[0]):
            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))
        yield (batch_crops, batch_y)

def train(model,model_name='vgg'):
    train_datagen = ImageDataGenerator(1./255,
                              width_shift_range=0.1,
                              height_shift_range=0.1,
                              shear_range=0.2,
                              zoom_range=0.2,)
    test_datagen = ImageDataGenerator(1./255)
    train_generator = train_datagen.flow_from_directory(
        train_data_dir,
        shuffle=True,
        target_size=IMAGE_SIZE,
        batch_size=batch_size,
        color_mode="rgb",
        classes=classes,
        class_mode='categorical',
        seed=42)
    # print(train_generator.class_indices)
    # imgs, labels = next(train_generator)
    # print(imgs[0])
    # print(labels[0])
    # add random crop
    
    
    validation_generator = test_datagen.flow_from_directory(
        test_data_dir,
        target_size=IMAGE_SIZE,
        batch_size=batch_size,
        color_mode="rgb",
        classes=classes,
        class_mode='categorical',
        seed=42)
    # print(validation_generator.class_indices)

    train_generator = crop_generator(train_generator, CROP_LENGTH)
    validation_generator=crop_generator(validation_generator,CROP_LENGTH)

    save_path=os.path.join('trained_model',model_name)
    if(not os.path.exists(save_path)):
        os.mkdir(save_path)
    tensorboard = TensorBoard(log_dir='./logs/{}'.format(model_name), batch_size=batch_size)
    model_names = (os.path.join(save_path,model_name+'.{epoch:02d}-{val_acc:.4f}.hdf5'))
    model_checkpoint = ModelCheckpoint(model_names,
                                    monitor='val_acc',
                                    verbose=1,
                                    save_best_only=True,
                                    save_weights_only=True)
    reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss', factor=0.1,
                                         patience=4, verbose=1)
    callbacks = [model_checkpoint,reduce_learning_rate,tensorboard]

    model.compile(loss='categorical_crossentropy',
        optimizer='adam',
        metrics=['accuracy'])
    model.fit_generator(train_generator,
        steps_per_epoch=nb_train_samples//batch_size,
        epochs=nb_epoch,
        callbacks=callbacks,
        validation_data=validation_generator,
        validation_steps=nb_validation_samples // batch_size
      )

# bn + prelu
def bn_prelu(x):
    x = BatchNormalization()(x)
    x = PReLU()(x)
    return x

def train_factory(MODEL_NAME):

    config = tf.ConfigProto()
    config.gpu_options.allocator_type = 'BFC'
    config.gpu_options.allow_growth = True
    set_session(tf.Session(config=config)) 

    model=None
    if(MODEL_NAME=='resnet_attention_56'):
        model=Resnet_Attention_56.Resnet_Attention_56(input_shape=(img_width,img_height,3),classes=charset_size)

    print(model.summary())
    train(model,MODEL_NAME)


def make_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('-m',"--model_name",type=str,
            help='select the model name that you want to train')
    return parser.parse_args()

if __name__ == '__main__':
    args = make_args()
    train_factory(args.model_name)
    
